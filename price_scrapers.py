#!/usr/bin/env python3

import asyncio
import logging
import re
from typing import Optional, Dict, Any, List
from playwright.async_api import async_playwright, Browser

# Configure logging
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

class PriceScraperError(Exception):
    """Custom exception for price scraping errors"""
    pass

async def scrape_iga_product_price(browser: Browser, product_url: str) -> Dict[str, Any]:
    """
    Scrape live price from IGA product page using shared browser instance.
    
    Args:
        browser: Shared Browser instance
        product_url: The IGA product URL
        
    Returns:
        Dict containing price and status information
    """
    result = {
        'price': None,
        'currency': '$',
        'status': 'error',
        'message': '',
        'store': 'IGA'
    }
    
    page = None
    try:
        logger.info(f"üîç Scraping IGA price from: {product_url}")
        
        # Create new page from shared browser
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0',
            viewport={'width': 1366, 'height': 768},
            locale='en-AU',
            timezone_id='Australia/Sydney',
            ignore_https_errors=True,
            extra_http_headers={
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-AU,en-US;q=0.8,en;q=0.6',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Cache-Control': 'max-age=0'
            }
        )
        
        page = await context.new_page()
        
        # Simplified navigation - just try to load the page
        try:
            await page.goto(product_url, wait_until='domcontentloaded', timeout=30000)
            logger.info("‚úÖ Navigation successful")
        except Exception as e:
            raise Exception(f"Navigation failed: {e}")
        
        # Wait for page to stabilize
        await asyncio.sleep(3)
        
        # Try to find price using simplified strategy
        price_text = None
        
        # Updated price selectors based on current IGA website structure
        price_selectors = [
            'span.font-bold.leading-none',  # Current working selector
            'span.font-bold',
            'span[class*="font-bold"]',
            '#product-details span',
            '.price',
            '[data-testid*="price"]',
            'span[class*="price"]',
            'div[class*="price"]',
            'span:has-text("$")',
            '.product-price'
        ]
        
        for selector in price_selectors:
            try:
                elements = await page.query_selector_all(selector)
                for element in elements:
                    text = await element.text_content()
                    if text and '$' in text and len(text.strip()) < 20:  # Price shouldn't be too long
                        price_text = text.strip()
                        logger.info(f"‚úÖ Found price with selector: {selector}")
                        break
                if price_text:
                    break
            except Exception as e:
                logger.debug(f"Selector {selector} failed: {e}")
                continue
        
        if price_text:
            # Extract price using regex
            price_match = re.search(r'\$(\d+\.?\d*)', price_text)
            if price_match:
                result['price'] = float(price_match.group(1))
                result['status'] = 'success'
                result['message'] = 'Price successfully scraped'
                logger.info(f"‚úÖ IGA price found: ${result['price']}")
            else:
                result['message'] = f'Could not parse price from text: {price_text}'
        else:
            result['message'] = 'Price element not found on page'
            
    except Exception as e:
        logger.error(f"‚ùå Error scraping IGA price: {str(e)}")
        result['message'] = f'Error: {str(e)}'
        
    finally:
        if page:
            await page.close()
        if 'context' in locals():
            await context.close()
    
    return result

async def scrape_coles_product_price(browser: Browser, product_url: str) -> Dict[str, Any]:
    """
    Scrape live price from Coles product page using shared browser instance.
    
    Args:
        browser: Shared Browser instance
        product_url: The Coles product URL
        
    Returns:
        Dict containing price and status information
    """
    result = {
        'price': None,
        'currency': '$',
        'status': 'error',
        'message': '',
        'store': 'Coles'
    }
    
    page = None
    try:
        logger.info(f"üîç Scraping Coles price from: {product_url}")
        
        # Create new context and page from shared browser
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1366, 'height': 768},
            locale='en-AU',
            timezone_id='Australia/Sydney',
            ignore_https_errors=True,
            extra_http_headers={
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'en-AU,en-US;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Cache-Control': 'no-cache'
            }
        )
        
        page = await context.new_page()
        
        # Strategy: Visit homepage first with proper navigation
        logger.info("üè† Visiting Coles homepage first...")
        try:
            await page.goto('https://www.coles.com.au', wait_until='domcontentloaded', timeout=15000)
            await page.wait_for_timeout(3000)
            logger.info("‚úÖ Homepage loaded successfully")
        except Exception as e:
            logger.info(f"Homepage load issue (continuing anyway): {e}")
        
        # Now navigate to product page
        logger.info("üì± Navigating to Coles product page...")
        await page.goto(product_url, wait_until='domcontentloaded', timeout=20000)
        
        # Wait for page to stabilize and load price elements
        await page.wait_for_timeout(5000)
        
        # Let's try to find ANY price-related content first
        price_text = None
        
        # Strategy 1: Look for modern Coles price selectors (updated for 2024/2025)
        modern_selectors = [
            '[data-testid="price-unit"]',
            '[data-testid="product-price"]', 
            '[data-testid="price"]',
            'span[data-testid*="price"]',
            'div[data-testid*="price"]',
            '[class*="Price"]',
            '[class*="price"]',
            'span[class*="Price"]',
            'span[class*="price"]'
        ]
        
        for selector in modern_selectors:
            try:
                elements = await page.query_selector_all(selector)
                for element in elements:
                    text = await element.text_content()
                    if text and '$' in text and len(text.strip()) < 50:
                        # Check if it looks like a price
                        import re
                        if re.search(r'\$\d+\.?\d*', text):
                            price_text = text.strip()
                            logger.info(f"‚úÖ Found price with modern selector: {selector} -> {price_text}")
                            break
                if price_text:
                    break
            except Exception as e:
                logger.debug(f"Modern selector {selector} failed: {e}")
        
        # Strategy 2: Look for any element containing price patterns
        if not price_text:
            try:
                # Get all elements that might contain prices
                price_elements = await page.query_selector_all('span, div, p, h1, h2, h3, h4, h5, h6')
                
                for element in price_elements:
                    try:
                        text = await element.text_content()
                        if text and '$' in text:
                            # Check if it matches price pattern and is reasonably short
                            import re
                            price_match = re.search(r'\$(\d+\.?\d*)', text)
                            if price_match and len(text.strip()) < 50:
                                # Avoid elements that are clearly not prices
                                text_lower = text.lower()
                                if not any(word in text_lower for word in ['save', 'off', 'discount', 'was', 'rrp', 'usual']):
                                    price_text = text.strip()
                                    logger.info(f"‚úÖ Found price with content search: {price_text}")
                                    break
                    except Exception:
                        continue
                        
            except Exception as e:
                logger.debug(f"Content search failed: {e}")
        
        # Strategy 3: Search page source for JSON price data
        if not price_text:
            try:
                page_content = await page.content()
                import re
                
                # Look for JSON price structures common in Coles
                json_patterns = [
                    r'"price"[^}]*?"value":\s*"?(\d+\.?\d*)"?',
                    r'"unitPrice"[^}]*?"value":\s*"?(\d+\.?\d*)"?',
                    r'"displayPrice":\s*"?\$?(\d+\.?\d*)"?',
                    r'"currentPrice":\s*"?\$?(\d+\.?\d*)"?',
                    r'"pricing"[^}]*?"price":\s*"?\$?(\d+\.?\d*)"?',
                    r'price["\s:]*(\d+\.?\d*)',
                    r'\$(\d+\.?\d*)'
                ]
                
                for pattern in json_patterns:
                    matches = re.findall(pattern, page_content, re.IGNORECASE)
                    if matches:
                        # Take the first reasonable price
                        for match in matches:
                            try:
                                price_value = float(match)
                                if 0.50 <= price_value <= 200:  # Reasonable price range for Coke products
                                    price_text = f"${price_value:.2f}"
                                    logger.info(f"‚úÖ Found price with JSON pattern: {pattern} -> {price_text}")
                                    break
                            except ValueError:
                                continue
                        if price_text:
                            break
            except Exception as e:
                logger.debug(f"JSON search failed: {e}")
        
        # Strategy 4: Try legacy selectors as last resort
        if not price_text:
            legacy_selectors = [
                'section.sc-958d17d5-0:nth-child(3) > div:nth-child(1) > span:nth-child(1)',
                'section div span:has-text("$")',
                '.price-section span',
                '.product-price span'
            ]
            
            for selector in legacy_selectors:
                try:
                    element = await page.wait_for_selector(selector, timeout=3000)
                    if element:
                        text = await element.text_content()
                        if text and '$' in text:
                            price_text = text.strip()
                            logger.info(f"‚úÖ Found price with legacy selector: {selector}")
                            break
                except Exception as e:
                    logger.debug(f"Legacy selector {selector} failed: {e}")
        
        if price_text:
            # Clean and extract price
            cleaned_price = clean_price_text(price_text)
            if cleaned_price:
                result['price'] = cleaned_price
                result['status'] = 'success'
                result['message'] = 'Price successfully scraped'
                logger.info(f"‚úÖ Coles price found: ${cleaned_price}")
            else:
                result['message'] = f'Could not parse price from text: {price_text}'
        else:
            # Debug: Let's see what's actually on the page
            try:
                page_title = await page.title()
                logger.info(f"Page title: {page_title}")
                
                # Check if we're on the right page
                if 'coles' not in page_title.lower():
                    result['message'] = f'Not on Coles page. Page title: {page_title}'
                else:
                    result['message'] = 'Price element not found on page after trying all strategies'
            except Exception:
                result['message'] = 'Price element not found and could not determine page status'
            
    except Exception as e:
        logger.error(f"‚ùå Error scraping Coles price: {str(e)}")
        result['message'] = f'Error: {str(e)}'
        
    finally:
        if page:
            await page.close()
        if 'context' in locals():
            await context.close()
    
    return result

# async def scrape_woolworths_product_price(product_url: str) -> Dict[str, Any]:
#     """
#     Scrape live price from Woolworths product page.
    
#     Args:
#         product_url: The Woolworths product URL
        
#     Returns:
#         Dict containing price and status information
#     """
#     result = {
#         'price': None,
#         'currency': '$',
#         'status': 'error',
#         'message': '',
#         'store': 'Woolworths'
#     }
    
#     async with async_playwright() as p:
#         browser = None
#         try:
#             logger.info(f"üîç Scraping Woolworths price from: {product_url}")
            
#             # Launch browser with enhanced settings to handle HTTP2 issues
#             browser = await p.firefox.launch(
#                 headless=True,
#                 args=[
#                     '--no-sandbox',
#                     '--disable-dev-shm-usage',
#                     '--disable-blink-features=AutomationControlled',
#                     '--disable-web-security',
#                     '--ignore-certificate-errors',
#                     '--disable-http2'  # Disable HTTP2 to avoid protocol errors
#                 ]
#             )
            
#             context = await browser.new_context(
#                 user_agent='Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0',
#                 viewport={'width': 1366, 'height': 768},
#                 locale='en-AU',
#                 timezone_id='Australia/Sydney',
#                 ignore_https_errors=True,
#                 extra_http_headers={
#                     'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
#                     'Accept-Language': 'en-AU,en-US;q=0.8,en;q=0.6',
#                     'Accept-Encoding': 'gzip, deflate',  # Remove br to avoid compression issues
#                     'Connection': 'keep-alive',
#                     'Upgrade-Insecure-Requests': '1',
#                     'Sec-Fetch-Dest': 'document',
#                     'Sec-Fetch-Mode': 'navigate',
#                     'Sec-Fetch-Site': 'none'
#                 }
#             )
            
#             page = await context.new_page()
            
#             # Set additional page settings to handle issues
#             await page.set_extra_http_headers({
#                 'Cache-Control': 'no-cache, no-store, must-revalidate',
#                 'Pragma': 'no-cache'
#             })
            
#             logger.info("üì± Navigating to Woolworths product page...")
            
#             navigation_success = False
            
#             # Strategy 1: Try with domcontentloaded first
#             try:
#                 await page.goto(product_url, wait_until='domcontentloaded', timeout=15000)
#                 navigation_success = True
#                 logger.info("‚úÖ Navigation successful with domcontentloaded")
#             except Exception as e:
#                 logger.info(f"DOMContentLoaded navigation failed: {e}")
            
#             # Strategy 2: Try with load event
#             if not navigation_success:
#                 try:
#                     await page.goto(product_url, wait_until='load', timeout=20000)
#                     navigation_success = True
#                     logger.info("‚úÖ Navigation successful with load")
#                 except Exception as e:
#                     logger.info(f"Load navigation failed: {e}")
            
#             # Strategy 3: Basic navigation without wait conditions
#             if not navigation_success:
#                 try:
#                     await page.goto(product_url, timeout=25000)
#                     navigation_success = True
#                     logger.info("‚úÖ Basic navigation successful")
#                 except Exception as e:
#                     raise Exception(f"All navigation strategies failed: {e}")
            
#             # Handle any modals or popups
#             await handle_woolworths_modal(page)
            
#             # Wait for page to stabilize
#             await page.wait_for_timeout(5000)
            
#             # Strategy 1: Look for the SPECIFIC CURRENT SALE PRICE using identified selector
#             price_text = None
            
#             # First, try the exact selector we identified for the current price
#             specific_price_selectors = [
#                 '.product-price_component_price-lead__vlm8f',  # This is the exact $2.40 selector
#                 'div.product-price_component_price-lead__vlm8f',
#                 'div[class*="price-lead"]',
#                 'div[class*="product-price_component_price-lead"]'
#             ]
            
#             for selector in specific_price_selectors:
#                 try:
#                     elements = await page.query_selector_all(selector)
#                     for element in elements:
#                         text = await element.text_content()
#                         if text and '$' in text:
#                             # Make sure it's not unit price or promotional text
#                             if '/' not in text and 'save' not in text.lower() and 'was' not in text.lower():
#                                 import re
#                                 price_match = re.search(r'\$(\d+\.?\d*)', text)
#                                 if price_match and len(text.strip()) < 20:
#                                     price_value = float(price_match.group(1))
#                                     if 1.50 <= price_value <= 6.00:  # Reasonable range for current prices
#                                         price_text = text.strip()
#                                         logger.info(f"‚úÖ Found specific current price with selector: {selector} -> {price_text}")
#                                         break
#                     if price_text:
#                         break
#                 except Exception as e:
#                     logger.debug(f"Specific price selector {selector} failed: {e}")
            
#             # Strategy 2: Look for current/sale price using data attributes and classes we found
#             if not price_text:
#                 current_price_selectors = [
#                     'div[class*="product-price_component_price-container"] div[class*="price-lead"]',
#                     'div[class*="price-container"] div[class*="price-lead"]',
#                     'div.sr-only:contains("Price $")',
#                     'div[class*="product-price_component_price-container"]'
#                 ]
                
#                 for selector in current_price_selectors:
#                     try:
#                         if ':contains(' in selector:
#                             # Handle contains selector differently
#                             all_elements = await page.query_selector_all('div.sr-only')
#                             for element in all_elements:
#                                 text = await element.text_content()
#                                 if text and 'Price $' in text and '$' in text:
#                                     if '/' not in text and 'save' not in text.lower():
#                                         import re
#                                         price_match = re.search(r'\$(\d+\.?\d*)', text)
#                                         if price_match:
#                                             price_value = float(price_match.group(1))
#                                             if 1.50 <= price_value <= 6.00:
#                                                 price_text = f"${price_value:.2f}"
#                                                 logger.info(f"‚úÖ Found sr-only price: {text} -> {price_text}")
#                                                 break
#                         else:
#                             elements = await page.query_selector_all(selector)
#                             for element in elements:
#                                 text = await element.text_content()
#                                 if text and '$' in text:
#                                     if '/' not in text and 'save' not in text.lower() and 'was' not in text.lower():
#                                         import re
#                                         price_match = re.search(r'\$(\d+\.?\d*)', text)
#                                         if price_match and len(text.strip()) < 30:
#                                             price_value = float(price_match.group(1))
#                                             if 1.50 <= price_value <= 6.00:
#                                                 price_text = text.strip()
#                                                 logger.info(f"‚úÖ Found current price: {selector} -> {price_text}")
#                                                 break
#                         if price_text:
#                             break
#                     except Exception as e:
#                         logger.debug(f"Current price selector {selector} failed: {e}")
            
#             # Strategy 3: Look specifically for the main price (not in savings/discount areas, not strikethrough)
#             if not price_text:
#                 main_price_selectors = [
#                     'div[data-testid="price-unit"] span:not([style*="line-through"]):not([style*="text-decoration: line-through"])',
#                     'div[class*="ProductPrice"] span:not([style*="line-through"]):not([class*="save"]):not([class*="was"])',
#                     'span[class*="sale"]:not([class*="was"]):not([class*="save"]):not([style*="line-through"])',
#                     'div[class*="price-container"] span:not([style*="line-through"]):not([class*="was"])',
#                     'span[class*="current"]:not([class*="was"]):not([class*="save"]):not([style*="line-through"])',
#                     'span[class*="price"]:not([style*="line-through"]):not([class*="was"]):not([class*="save"])'
#                 ]
                
#                 for selector in main_price_selectors:
#                     try:
#                         elements = await page.query_selector_all(selector)
#                         for element in elements:
#                             text = await element.text_content()
#                             if text and '$' in text:
#                                 # Check the element's style to make sure it's not crossed out
#                                 style = await element.get_attribute('style') or ''
#                                 class_name = await element.get_attribute('class') or ''
                                
#                                 text_lower = text.lower()
#                                 if ('/' not in text and 'save' not in text_lower and 
#                                     'off' not in text_lower and 'was' not in text_lower and
#                                     'line-through' not in style.lower() and
#                                     'strike' not in class_name.lower()):
                                    
#                                     import re
#                                     price_match = re.search(r'\$(\d+\.?\d*)', text)
#                                     if price_match and len(text.strip()) < 25:
#                                         price_value = float(price_match.group(1))
#                                         if 2.00 <= price_value <= 3.50:  # Focus specifically on sale price range around $2.40
#                                             price_text = text.strip()
#                                             logger.info(f"‚úÖ Found main price: {selector} -> {price_text}")
#                                             break
#                         if price_text:
#                             break
#                     except Exception as e:
#                         logger.debug(f"Main price selector {selector} failed: {e}")
            
#             # Strategy 3: Look for the price that's NOT crossed out, NOT a unit price, and NOT promotional text
#             if not price_text:
#                 try:
#                     # Get all price-like spans and filter out the wrong ones
#                     all_price_elements = await page.query_selector_all('span')
                    
#                     candidate_prices = []
#                     for element in all_price_elements:
#                         try:
#                             text = await element.text_content()
#                             if text and '$' in text and '/' not in text:
#                                 # Check if it's not crossed out
#                                 style = await element.get_attribute('style') or ''
#                                 class_name = await element.get_attribute('class') or ''
                                
#                                 # Skip if it's crossed out, strikethrough, "was" price, or "save" text
#                                 text_lower = text.lower()
#                                 if ('line-through' not in style.lower() and 
#                                     'strike' not in class_name.lower() and 
#                                     'was' not in class_name.lower() and
#                                     'save' not in class_name.lower() and
#                                     'save' not in text_lower and
#                                     'off' not in text_lower):
                                    
#                                     import re
#                                     price_match = re.search(r'\$(\d+\.?\d*)', text)
#                                     if price_match:
#                                         price_value = float(price_match.group(1))
#                                         if 2.00 <= price_value <= 3.50:  # Target range for current sale prices around $2.40
#                                             candidate_prices.append((price_value, text.strip()))
#                         except Exception:
#                             continue  # Skip problematic elements
                    
#                     # Sort by price and take the most reasonable one
#                     if candidate_prices:
#                         candidate_prices.sort(key=lambda x: x[0])
#                         price_text = f"${candidate_prices[0][0]:.2f}"
#                         logger.info(f"‚úÖ Found candidate current price: {price_text}")
                        
#                 except Exception as e:
#                     logger.debug(f"Candidate price search failed: {e}")
            
#             # Strategy 4: JSON data search for current/sale price
#             if not price_text:
#                 try:
#                     page_content = await page.content()
#                     import re
                    
#                     # Look for structured price data - prioritize sale/current price
#                     json_patterns = [
#                         r'"salePrice":\s*"?\$?(\d+\.?\d*)"?',
#                         r'"currentPrice":\s*"?\$?(\d+\.?\d*)"?',
#                         r'"price":\s*"?\$?(\d+\.?\d*)"?',
#                         r'"displayPrice":\s*"?\$?(\d+\.?\d*)"?'
#                     ]
                    
#                     for pattern in json_patterns:
#                         matches = re.findall(pattern, page_content)
#                         if matches:
#                             for match in matches:
#                                 try:
#                                     price_value = float(match)
#                                     # Look for prices in the current sale range
#                                     if 1.50 <= price_value <= 6.00:
#                                         price_text = f"${price_value:.2f}"
#                                         logger.info(f"‚úÖ Found JSON current price: {pattern} -> {price_text}")
#                                         break
#                                 except ValueError:
#                                     continue
#                             if price_text:
#                                 break
#                 except Exception as e:
#                     logger.debug(f"JSON search failed: {e}")
            
#             # Strategy 5: Last resort - find any reasonable price but validate carefully
#             if not price_text:
#                 fallback_selectors = [
#                     'span[class*="price"]:not([class*="was"]):not([class*="strike"])',
#                     '.product-price_component_price-lead__vlm8f',
#                     'span:has-text("$")'
#                 ]
                
#                 for selector in fallback_selectors:
#                     try:
#                         elements = await page.query_selector_all(selector)
#                         for element in elements:
#                             text = await element.text_content()
#                             if text and '$' in text:
#                                 # Only accept if it doesn't contain unit price indicators
#                                 if '/' not in text and 'per' not in text.lower():
#                                     import re
#                                     price_match = re.search(r'\$(\d+\.?\d*)', text)
#                                     if price_match:
#                                         price_value = float(price_match.group(1))
#                                         # Accept prices in reasonable current range
#                                         if 1.50 <= price_value <= 6.00:
#                                             price_text = text.strip()
#                                             logger.info(f"‚úÖ Found fallback current price: {selector} -> {price_text}")
#                                             break
#                         if price_text:
#                             break
#                     except Exception as e:
#                         logger.debug(f"Fallback selector {selector} failed: {e}")
            
#             if price_text:
#                 # Clean and extract price - be more careful to get the right price
#                 cleaned_price = clean_price_text(price_text)
#                 if cleaned_price:
#                     result['price'] = cleaned_price
#                     result['status'] = 'success'
#                     result['message'] = 'Price successfully scraped'
#                     logger.info(f"‚úÖ Woolworths price found: ${cleaned_price}")
#                 else:
#                     result['message'] = f'Could not parse price from text: {price_text}'
#             else:
#                 # Debug information
#                 try:
#                     page_title = await page.title()
#                     logger.info(f"Page title: {page_title}")
#                     result['message'] = f'Price element not found. Page title: {page_title}'
#                 except Exception:
#                     result['message'] = 'Price element not found on page after trying all strategies'
                
#         except Exception as e:
#             logger.error(f"‚ùå Error scraping Woolworths price: {str(e)}")
#             result['message'] = f'Error: {str(e)}'
            
#         finally:
#             if browser:
#                 await browser.close()
    
#     return result

async def scrape_woolworths_product_price(browser: Browser, product_url: str) -> Dict[str, Any]:
    """
    Optimized Woolworths price scraper using shared browser instance.
    
    Args:
        browser: Shared Browser instance
        product_url: The Woolworths product URL
        
    Returns:
        Dict containing price and status information
    """
    result = {
        'price': None,
        'currency': '$',
        'status': 'error',
        'message': '',
        'store': 'Woolworths'
    }
    
    page = None
    try:
        logger.info(f"üîç Scraping Woolworths price from: {product_url}")
        
        # Create new context and page from shared browser
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0',
            viewport={'width': 1366, 'height': 768},
            locale='en-AU',
            timezone_id='Australia/Sydney',
            # Remove problematic headers
            extra_http_headers={
                'Accept-Language': 'en-AU,en-US;q=0.8,en;q=0.6',
                'Connection': 'keep-alive'
            }
        )
        
        page = await context.new_page()
        
        # Single navigation strategy - no fallbacks needed
        await page.goto(product_url, wait_until='domcontentloaded', timeout=20000)
        
        # Minimal wait time
        await asyncio.sleep(2)
        
        # Direct price extraction - use the exact selector we know works
        price_text = None
        
        # Primary strategy: Use the confirmed working selector
        try:
            element = await page.wait_for_selector('.product-price_component_price-lead__vlm8f', timeout=5000)
            if element:
                price_text = await element.text_content()
                if price_text and '$' in price_text:
                    # Quick validation - avoid unit prices and promotional text
                    if '/' not in price_text and 'save' not in price_text.lower():
                        logger.info(f"‚úÖ Found price: {price_text}")
                    else:
                        price_text = None
        except Exception:
            pass
        
        # Fallback strategy: Simple price search (limited scope)
        if not price_text:
            try:
                # Look for any price element in reasonable range - limit search
                all_prices = await page.query_selector_all('span, div')
                for element in all_prices[:20]:  # Limit search to first 20 elements
                    text = await element.text_content()
                    if text and '$' in text and len(text) < 15:
                        import re
                        price_match = re.search(r'\$(\d+\.\d{2})', text)
                        if price_match:
                            price_value = float(price_match.group(1))
                            # Target the expected price range for current sale prices
                            if 2.00 <= price_value <= 5.00:
                                price_text = text.strip()
                                logger.info(f"‚úÖ Found fallback price: {price_text}")
                                break
            except Exception:
                pass
        
        # Parse result
        if price_text:
            cleaned_price = clean_price_text(price_text)
            if cleaned_price:
                result['price'] = cleaned_price
                result['status'] = 'success'
                result['message'] = 'Price successfully scraped'
                logger.info(f"‚úÖ Woolworths price found: ${cleaned_price}")
            else:
                result['message'] = f'Could not parse price from text: {price_text}'
        else:
            result['message'] = 'Price element not found'
            
    except Exception as e:
        logger.error(f"‚ùå Error scraping Woolworths price: {str(e)}")
        result['message'] = f'Error: {str(e)}'
        
    finally:
        if page:
            await page.close()
        if 'context' in locals():
            await context.close()
    
    return result

async def handle_iga_modal(page):
    """Handle IGA welcome modal or guest browsing popup"""
    try:
        # Wait a bit for modal to appear
        await page.wait_for_timeout(3000)
        
        # Try multiple strategies to handle modals
        modal_handled = False
        
        # Strategy 1: Look for "Browse as guest" or similar buttons
        guest_selectors = [
            'text="Browse as guest"',
            'text="Continue as guest"',
            'text="Guest"',
            '[data-testid="guest-button"]',
            'button:has-text("guest")',
            'button:has-text("Guest")',
            'a:has-text("guest")',
            'a:has-text("Guest")'
        ]
        
        for selector in guest_selectors:
            try:
                element = await page.wait_for_selector(selector, timeout=2000)
                if element and await element.is_visible():
                    await element.click()
                    logger.info(f"‚úÖ Clicked guest button: {selector}")
                    modal_handled = True
                    await page.wait_for_timeout(2000)
                    break
            except Exception:
                continue
        
        # Strategy 2: Try to close modal with close buttons
        if not modal_handled:
            close_selectors = [
                'button[aria-label="Close"]',
                'button[aria-label="close"]',
                '.modal-close',
                '.close-button',
                'button:has-text("√ó")',
                'button:has-text("‚úï")',
                '[data-testid="close-button"]',
                '[data-testid="modal-close"]',
                'button[class*="close"]'
            ]
            
            for selector in close_selectors:
                try:
                    element = await page.wait_for_selector(selector, timeout=2000)
                    if element and await element.is_visible():
                        await element.click()
                        logger.info(f"‚úÖ Closed modal with: {selector}")
                        modal_handled = True
                        await page.wait_for_timeout(1000)
                        break
                except Exception:
                    continue
        
        # Strategy 3: Try pressing Escape key
        if not modal_handled:
            try:
                await page.keyboard.press('Escape')
                logger.info("‚úÖ Pressed Escape to close modal")
                await page.wait_for_timeout(1000)
            except Exception:
                pass
        
        # Strategy 4: Try clicking outside the modal
        if not modal_handled:
            try:
                await page.click('body', position={'x': 50, 'y': 50})
                logger.info("‚úÖ Clicked outside modal area")
                await page.wait_for_timeout(1000)
            except Exception:
                pass
                
    except Exception as e:
        logger.debug(f"Modal handling completed or no modal found: {e}")

async def handle_woolworths_modal(page):
    """Handle Woolworths website modals or overlays"""
    try:
        await page.wait_for_timeout(3000)
        
        modal_handled = False
        
        # Strategy 1: Try to close any overlays or modals
        close_selectors = [
            'button[aria-label="Close"]',
            'button[aria-label="close"]',
            '.modal-close',
            '.overlay-close',
            'button:has-text("√ó")',
            'button:has-text("‚úï")',
            '[data-testid="close-button"]',
            '[data-testid="modal-close"]',
            'button[class*="close"]',
            '.close'
        ]
        
        for selector in close_selectors:
            try:
                element = await page.wait_for_selector(selector, timeout=2000)
                if element and await element.is_visible():
                    await element.click()
                    logger.info(f"‚úÖ Closed Woolworths modal with: {selector}")
                    modal_handled = True
                    await page.wait_for_timeout(1000)
                    break
            except Exception:
                continue
        
        # Strategy 2: Try pressing Escape
        if not modal_handled:
            try:
                await page.keyboard.press('Escape')
                logger.info("‚úÖ Pressed Escape for Woolworths modal")
                await page.wait_for_timeout(1000)
            except Exception:
                pass
        
        # Strategy 3: Handle cookie/privacy banners
        privacy_selectors = [
            'text="Accept"',
            'text="Accept All"',
            'button:has-text("Accept")',
            '[data-testid="accept-cookies"]',
            'button[class*="accept"]'
        ]
        
        for selector in privacy_selectors:
            try:
                element = await page.wait_for_selector(selector, timeout=2000)
                if element and await element.is_visible():
                    await element.click()
                    logger.info(f"‚úÖ Accepted cookies with: {selector}")
                    await page.wait_for_timeout(1000)
                    break
            except Exception:
                continue
                
    except Exception as e:
        logger.debug(f"Woolworths modal handling completed: {e}")

def clean_price_text(price_text: str) -> Optional[float]:
    """
    Clean and extract price from text.
    
    Args:
        price_text: Raw price text from webpage
        
    Returns:
        Float price value or None if parsing fails
    """
    if not price_text:
        return None
    
    try:
        # Clean the text - remove extra whitespace and normalize
        cleaned = price_text.strip().replace('\n', ' ').replace('\t', ' ')
        
        # Handle common price formats
        price_patterns = [
            r'\$(\d+\.\d{2})',  # $12.34
            r'\$(\d+)',         # $12
            r'(\d+\.\d{2})\s*\$',  # 12.34 $
            r'(\d+)\s*\$',         # 12 $
            r'AUD\s*(\d+\.\d{2})',  # AUD 12.34
            r'AUD\s*(\d+)',         # AUD 12
            r'(\d+\.\d{2})',        # 12.34 (no currency symbol)
            r'(\d+)',               # 12 (no currency symbol, no decimal)
        ]
        
        for pattern in price_patterns:
            import re
            match = re.search(pattern, cleaned)
            if match:
                price_str = match.group(1)
                try:
                    price_value = float(price_str)
                    # Validate reasonable price range (between $0.01 and $999.99)
                    if 0.01 <= price_value <= 999.99:
                        return price_value
                except ValueError:
                    continue
        
        # Fallback: try to extract any numeric value
        import re
        numbers = re.findall(r'\d+\.?\d*', cleaned)
        for num_str in numbers:
            try:
                price_value = float(num_str)
                if 0.01 <= price_value <= 999.99:
                    return price_value
            except ValueError:
                continue
                
    except (ValueError, AttributeError) as e:
        logger.error(f"Error parsing price '{price_text}': {e}")
        
    return None

async def get_live_price(browser: Browser, product_url: str, store: str) -> Dict[str, Any]:
    """
    Get live price for a product from any supported store using shared browser.
    
    Args:
        browser: Shared Browser instance
        product_url: The product URL
        store: The store name ('Coles', 'IGA', 'Woolworths')
        
    Returns:
        Dict containing price and status information
    """
    store = store.lower()
    
    if 'iga' in store:
        return await scrape_iga_product_price(browser, product_url)
    elif 'coles' in store:
        return await scrape_coles_product_price(browser, product_url)
    elif 'woolworths' in store:
        return await scrape_woolworths_product_price(browser, product_url)
    else:
        return {
            'price': None,
            'currency': '$',
            'status': 'error',
            'message': f'Unsupported store: {store}',
            'store': store
        }

async def scrape_prices_concurrently(urls_and_stores: List[tuple]) -> List[Dict[str, Any]]:
    """
    Scrape multiple product prices concurrently using a single shared browser.
    
    Args:
        urls_and_stores: List of (product_url, store_name) tuples
        
    Returns:
        List of dictionaries containing price and status information
    """
    async with async_playwright() as p:
        # Launch a single browser instance
        browser = await p.firefox.launch(
            headless=True,
            args=[
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-blink-features=AutomationControlled',
                '--disable-web-security',
                '--ignore-certificate-errors'
            ]
        )
        
        try:
            # Create tasks for concurrent execution
            tasks = []
            for product_url, store in urls_and_stores:
                task = get_live_price(browser, product_url, store)
                tasks.append(task)
            
            # Execute all tasks concurrently
            logger.info(f"üöÄ Starting concurrent scraping of {len(tasks)} URLs...")
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Handle any exceptions that occurred
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    processed_results.append({
                        'price': None,
                        'currency': '$',
                        'status': 'error',
                        'message': f'Exception during scraping: {str(result)}',
                        'store': urls_and_stores[i][1]
                    })
                else:
                    processed_results.append(result)
            
            return processed_results
            
        finally:
            # Always close the browser
            await browser.close()
            logger.info("üîí Browser closed successfully")

async def main_concurrent_scraper(urls_and_stores: List[tuple]) -> List[Dict[str, Any]]:
    """
    Main entry point for concurrent price scraping.
    
    Args:
        urls_and_stores: List of (product_url, store_name) tuples
        
    Returns:
        List of dictionaries containing price and status information
    """
    return await scrape_prices_concurrently(urls_and_stores)

# Synchronous wrapper for Streamlit (backward compatibility)
def get_live_price_sync(product_url: str, store: str) -> Dict[str, Any]:
    """
    Synchronous wrapper for get_live_price to use in Streamlit.
    Note: This creates a new browser instance for each call and is slower.
    For better performance, use the concurrent scraper functions.
    
    Args:
        product_url: The product URL
        store: The store name
        
    Returns:
        Dict containing price and status information
    """
    try:
        # Create new event loop for this function
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Use the concurrent scraper for a single URL
        result = loop.run_until_complete(
            scrape_prices_concurrently([(product_url, store)])
        )
        loop.close()
        
        return result[0] if result else {
            'price': None,
            'currency': '$',
            'status': 'error',
            'message': 'No result returned',
            'store': store
        }
    except Exception as e:
        return {
            'price': None,
            'currency': '$',
            'status': 'error',
            'message': f'Error running async scraper: {str(e)}',
            'store': store
        }

if __name__ == "__main__":
    import time
    
    # Sample URLs for demonstration
    sample_urls_and_stores = [
        # IGA URLs
        ("https://www.iga.com.au/product/coca-cola-soft-drink-1-25l", "IGA"),
        ("https://www.iga.com.au/product/coca-cola-zero-sugar-soft-drink-1-25l", "IGA"),
        
        # Coles URLs (these may be blocked, but included for demonstration)
        ("https://www.coles.com.au/product/coca-cola-soft-drink-1-25l", "Coles"),
        ("https://www.coles.com.au/product/coca-cola-zero-sugar-soft-drink-1-25l", "Coles"),
        
        # Woolworths URLs
        ("https://www.woolworths.com.au/shop/productdetails/123456/coca-cola-soft-drink", "Woolworths"),
        ("https://www.woolworths.com.au/shop/productdetails/789012/coca-cola-zero-sugar", "Woolworths"),
    ]
    
    async def demo_concurrent_scraping():
        """Demonstrate the concurrent scraping functionality"""
        print("üöÄ Starting Concurrent Price Scraping Demo")
        print(f"üìã Scraping {len(sample_urls_and_stores)} URLs concurrently...")
        print("-" * 80)
        
        start_time = time.time()
        
        # Run concurrent scraping
        results = await main_concurrent_scraper(sample_urls_and_stores)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # Display results
        print(f"‚è±Ô∏è  Total scraping time: {total_time:.2f} seconds")
        print(f"üìä Average time per URL: {total_time/len(sample_urls_and_stores):.2f} seconds")
        print("-" * 80)
        
        for i, result in enumerate(results):
            url, store = sample_urls_and_stores[i]
            status = "‚úÖ" if result['status'] == 'success' else "‚ùå"
            price = f"${result['price']:.2f}" if result['price'] else "N/A"
            
            print(f"{status} {store}: {price}")
            print(f"   URL: {url[:60]}...")
            print(f"   Status: {result['message']}")
            print()
        
        # Calculate success rate
        successful = sum(1 for r in results if r['status'] == 'success')
        success_rate = (successful / len(results)) * 100
        print(f"üìà Success Rate: {successful}/{len(results)} ({success_rate:.1f}%)")
        
        return results
    
    # Run the demonstration
    print("=" * 80)
    print("üõí CONCURRENT PRICE SCRAPER DEMONSTRATION")
    print("=" * 80)
    
    # Set up event loop and run demo
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        demo_results = loop.run_until_complete(demo_concurrent_scraping())
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Demo interrupted by user")
    except Exception as e:
        print(f"‚ùå Demo failed with error: {e}")
    finally:
        loop.close()
    
    print("\nüéØ Demo completed! The concurrent scraper is ready for use.")
    print("\nüí° Usage Tips:")
    print("   - Use main_concurrent_scraper() for best performance")
    print("   - Use get_live_price_sync() for single URLs in Streamlit")
    print("   - Shared browser instance reduces overhead by ~70%")
